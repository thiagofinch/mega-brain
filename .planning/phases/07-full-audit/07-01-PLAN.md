---
phase: 07-full-audit
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - core/intelligence/audit_layers.py
  - docs/audit/AUDIT-REPORT.json
  - docs/audit/AUDIT-REPORT.md
autonomous: true
requirements:
  - AUDIT-01
  - AUDIT-02
  - AUDIT-03
  - AUDIT-04
must_haves:
  truths:
    - "Every file in repo has a layer classification (L1, L2, L3, NEVER, DELETE, REVIEW)"
    - "Classification follows rules in CONTEXT.md exactly"
    - "Audit report exists in both JSON and MD formats"
    - "finance-agent and talent-agent marked for deletion"
  artifacts:
    - path: "core/intelligence/audit_layers.py"
      provides: "Layer classification audit script"
      min_lines: 150
    - path: "docs/audit/AUDIT-REPORT.json"
      provides: "Structured classification data"
      contains: "classification"
    - path: "docs/audit/AUDIT-REPORT.md"
      provides: "Human-readable audit report"
      contains: "Layer Distribution"
  key_links:
    - from: "audit_layers.py"
      to: "AUDIT-REPORT.json"
      via: "JSON output generation"
      pattern: "json\\.dump"
    - from: "audit_layers.py"
      to: "AUDIT-REPORT.md"
      via: "Markdown report generation"
      pattern: "write.*\\.md"
---

<objective>
Create a comprehensive audit of the entire mega-brain repository, classifying every file and folder into layers (L1/L2/L3) plus special categories (NEVER/DELETE/REVIEW).

Purpose: Enable NPM packaging by knowing exactly what goes into each distribution layer
Output: Python audit script + JSON/MD reports in docs/audit/
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-full-audit/07-CONTEXT.md
@.gitignore
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create layer audit Python script</name>
  <files>core/intelligence/audit_layers.py</files>
  <action>
Create a Python script (stdlib only + PyYAML) that:

1. **Classification Rules** (from CONTEXT.md decisions):

   ```python
   L1_PATTERNS = {
       # Core engine - machine/shell
       'bin/', 'core/', '.claude/' (most of it), 'agents/conclave/',
       'agents/_templates/', 'docs/' (public docs),
       # Empty structures with .gitkeep
       'inbox/.gitkeep', 'knowledge/.gitkeep', 'agents/minds/.gitkeep',
       'agents/cargo/.gitkeep', 'artifacts/*/.gitkeep'
   }

   L2_PATTERNS = {
       # Absorbed content (everything L1 + populated data)
       'agents/minds/**' (populated), 'agents/cargo/**' (populated),
       'knowledge/dossiers/**', 'knowledge/playbooks/**',
       'knowledge/dna/**', 'knowledge/sources/**',
       'artifacts/insights/**', 'artifacts/chunks/**'
   }

   L3_PATTERNS = {
       # Personal - never distributed
       'inbox/**' (actual content, not .gitkeep),
       'logs/**', '.claude/sessions/', '.claude/mission-control/',
       'agents/sua-empresa/**'
   }

   NEVER_PATTERNS = {
       # Always gitignored in ALL layers
       '.env', 'credentials.json', 'token.json', '*.key', '*.pem',
       '*.secret', '.mcp.json', 'settings.local.json', 'node_modules/'
   }

   DELETE_PATTERNS = {
       'finance-agent', 'talent-agent', # obsolete agents
       # Plus any discovered via search
   }

   REVIEW_PATTERNS = {
       # Mark for human review if doesn't fit clearly
   }
   ```

2. **Scanning Logic**:
   - Walk entire repo excluding .git/ and node_modules/
   - For each path, determine classification
   - Use directory-level classification where all children match
   - Fall down to file-level for special cases

3. **Output Data Structure**:
   ```python
   {
       "generated_at": "ISO timestamp",
       "repo_root": "/path/to/mega-brain",
       "summary": {
           "total_items": N,
           "by_layer": {"L1": N, "L2": N, "L3": N, "NEVER": N, "DELETE": N, "REVIEW": N}
       },
       "classifications": [
           {"path": "bin/", "layer": "L1", "type": "directory", "reason": "Core CLI tools"},
           {"path": ".env", "layer": "NEVER", "type": "file", "reason": "Secrets"},
           ...
       ],
       "delete_candidates": [
           {"path": "...", "reason": "Obsolete agent"}
       ],
       "review_needed": [
           {"path": "...", "reason": "Unclear classification"}
       ]
   }
   ```

4. **CLI Interface**:
   ```bash
   python3 core/intelligence/audit_layers.py [--output-dir docs/audit] [--verbose]
   ```

Key implementation notes:
- Use pathlib for cross-platform paths
- Classify from most specific to least specific (DELETE before L3 before L2 before L1)
- Include .claude/jarvis/ in L1 per user decision
- Skip binary/media files in detailed listing but include in counts
  </action>
  <verify>
    <automated>python3 core/intelligence/audit_layers.py --help 2>&amp;1 | grep -q "usage\|output"</automated>
  </verify>
  <done>Script exists with CLI, can run without errors, implements classification rules from CONTEXT.md</done>
</task>

<task type="auto">
  <name>Task 2: Execute audit and generate reports</name>
  <files>docs/audit/AUDIT-REPORT.json, docs/audit/AUDIT-REPORT.md</files>
  <action>
1. Create docs/audit/ directory if not exists

2. Run the audit script:
   ```bash
   python3 core/intelligence/audit_layers.py --output-dir docs/audit
   ```

3. The script should generate both files:
   - **AUDIT-REPORT.json**: Structured data per Task 1 spec
   - **AUDIT-REPORT.md**: Human-readable with:
     ```markdown
     # Mega Brain Layer Audit Report

     **Generated:** YYYY-MM-DD HH:MM
     **Total Items Classified:** N

     ## Summary

     | Layer | Count | % |
     |-------|-------|---|
     | L1 (Community) | N | X% |
     | L2 (Premium) | N | X% |
     | L3 (Personal) | N | X% |
     | NEVER | N | X% |
     | DELETE | N | X% |
     | REVIEW | N | X% |

     ## Delete Candidates

     | Path | Reason |
     |------|--------|
     | ... | ... |

     ## Needs Review

     | Path | Reason |
     |------|--------|
     | ... | ... |

     ## Layer Breakdown

     ### L1 (Community - npm package)

     - bin/
     - core/
     - ...

     ### L2 (Premium - populated)

     - knowledge/dossiers/
     - ...

     ### L3 (Personal - never distributed)

     - inbox/
     - logs/
     - ...
     ```

4. Verify both files contain valid data:
   - JSON is parseable
   - MD has expected sections
   - All 6 categories present in summary
  </action>
  <verify>
    <automated>python3 -c "import json; d=json.load(open('docs/audit/AUDIT-REPORT.json')); assert 'summary' in d and 'by_layer' in d['summary'], 'Missing required structure'"</automated>
  </verify>
  <done>JSON report valid with all layers, MD report has summary table and delete candidates section, finance-agent and talent-agent listed in delete candidates</done>
</task>

<task type="auto">
  <name>Task 3: Validate audit completeness</name>
  <files>docs/audit/AUDIT-REPORT.json</files>
  <action>
Create a validation check that confirms:

1. **No unclassified items**: Every scanned item has a classification
2. **DELETE candidates found**: finance-agent, talent-agent identified
3. **Classification accuracy**: Spot-check 5 known paths:
   - `core/` should be L1
   - `inbox/` should be L3 (content) or L1 (.gitkeep)
   - `.env` should be NEVER
   - `agents/minds/` should be L2 (populated) or L1 (.gitkeep only)
   - `logs/` should be L3

Run validation:
```python
import json

with open('docs/audit/AUDIT-REPORT.json') as f:
    data = json.load(f)

# Check completeness
assert data['summary']['total_items'] > 0, "No items classified"
assert sum(data['summary']['by_layer'].values()) == data['summary']['total_items'], "Items missing classification"

# Check DELETE candidates
delete_paths = [d['path'] for d in data.get('delete_candidates', [])]
assert any('finance' in p or 'talent' in p for p in delete_paths), "finance-agent or talent-agent not found in delete candidates"

print(f"Audit validated: {data['summary']['total_items']} items classified")
print(f"Delete candidates: {len(delete_paths)}")
```
  </action>
  <verify>
    <automated>python3 -c "import json; d=json.load(open('docs/audit/AUDIT-REPORT.json')); assert d['summary']['total_items'] > 50, 'Too few items'; print(f\"Audit OK: {d['summary']['total_items']} items\")"</automated>
  </verify>
  <done>All items classified, no unclassified items, DELETE candidates include finance/talent agents, spot checks pass</done>
</task>

</tasks>

<verification>
1. `python3 core/intelligence/audit_layers.py --help` runs without error
2. `docs/audit/AUDIT-REPORT.json` exists and is valid JSON
3. `docs/audit/AUDIT-REPORT.md` exists with summary table
4. JSON summary shows counts for all 6 categories (L1, L2, L3, NEVER, DELETE, REVIEW)
5. DELETE candidates list contains finance-agent and/or talent-agent paths
</verification>

<success_criteria>
- [ ] Audit script created with classification logic per CONTEXT.md
- [ ] Script runs successfully on repo
- [ ] JSON report generated with all items classified
- [ ] MD report generated with readable summary
- [ ] DELETE candidates identified (finance-agent, talent-agent)
- [ ] No items left unclassified (REVIEW category for ambiguous only)
</success_criteria>

<output>
After completion, create `.planning/phases/07-full-audit/07-01-SUMMARY.md`
</output>
