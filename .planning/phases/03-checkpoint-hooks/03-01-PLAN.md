---
phase: 03-checkpoint-hooks
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - .claude/hooks/pipeline_checkpoint.py
  - .claude/mission-control/PIPELINE-STATE.json
autonomous: true
requirements:
  - HOOK-01
  - HOOK-02
  - HOOK-03

must_haves:
  truths:
    - "Hook saves state after each pipeline phase completes"
    - "State includes phase name, files processed, and timestamp"
    - "Hook allows retry of a phase if it fails"
    - "Hook is integrated with settings.json PostToolUse"
  artifacts:
    - path: ".claude/hooks/pipeline_checkpoint.py"
      provides: "Checkpoint saving logic for pipeline phases 1-3"
      min_lines: 150
    - path: ".claude/mission-control/PIPELINE-STATE.json"
      provides: "Pipeline state persistence file"
  key_links:
    - from: ".claude/hooks/pipeline_checkpoint.py"
      to: ".claude/mission-control/PIPELINE-STATE.json"
      via: "JSON read/write operations"
      pattern: "PIPELINE-STATE"
    - from: ".claude/hooks/pipeline_checkpoint.py"
      to: ".claude/settings.json"
      via: "PostToolUse hook registration"
      pattern: "PostToolUse"
---

<objective>
Implement pipeline checkpoint hooks that save state after each pipeline phase (Ingest, Chunk, Canonical) completes.

Purpose: Enable resumption of pipeline processing if a phase fails, preventing re-processing of already completed phases.

Output:
- Python hook script for checkpoint management
- JSON state file for persistence
- Integration with settings.json
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

Pipeline phases from core/workflows/wf-pipeline-full.yaml:
- Phase 1: FOUNDATION (normalize entities, detect roles)
- Phase 2: INTELLIGENCE (analyze themes)
- Phase 3: EXTRACTION (extract DNA)
- Phase 4: PIPELINE (process batches)
- Phase 5: VALIDATION (validate cascading)

For this phase, we focus on Phases 1-3 (Ingest, Chunk, Canonical in pipeline terminology):
- Phase 1 (Ingest): File download/copy, metadata extraction
- Phase 2 (Chunk): Text chunking, semantic segmentation
- Phase 3 (Canonical): Entity resolution, canonical form creation

Reference existing hook patterns from:
- .claude/hooks/post_batch_cascading.py (PostToolUse pattern, JSON logging)
- .claude/hooks/session_autosave_v2.py (state persistence pattern)

Existing state file location pattern:
- .claude/mission-control/ (contains MISSION-STATE.json, other state files)
</context>

<interfaces>
From .claude/hooks/post_batch_cascading.py (existing pattern):
```python
# Hook input/output pattern
def main():
    input_data = sys.stdin.read()
    hook_input = json.loads(input_data) if input_data else {}
    tool_input = hook_input.get('tool_input', {})
    # ... process ...
    output = {'continue': True, 'feedback': None}
    print(json.dumps(output))

# Logging pattern
def log_action(action: Dict) -> None:
    with open(LOG_PATH, 'a', encoding='utf-8') as f:
        f.write(json.dumps(action, ensure_ascii=False) + '\n')
```

From settings.json (hook registration):
```json
{
  "hooks": {
    "PostToolUse": [
      {
        "matcher": "Edit|Write|MultiEdit",
        "hooks": [
          {"type": "command", "command": "python3 .claude/hooks/hookname.py", "timeout": 5000}
        ]
      }
    ]
  }
}
```
</interfaces>

<tasks>

<task type="auto">
  <name>Task 1: Create pipeline_checkpoint.py hook</name>
  <files>.claude/hooks/pipeline_checkpoint.py</files>
  <action>
Create the checkpoint hook with the following structure:

1. **Header and imports** (~15 lines):
   - Shebang: #!/usr/bin/env python3
   - Docstring explaining purpose, RULE integration (state management)
   - Imports: os, sys, json, re, datetime, pathlib.Path

2. **Configuration** (~20 lines):
   - PROJECT_DIR from env var CLAUDE_PROJECT_DIR or '.'
   - STATE_PATH = PROJECT_DIR / '.claude/mission-control/PIPELINE-STATE.json'
   - LOG_PATH = PROJECT_DIR / 'logs/pipeline-checkpoints.jsonl'
   - Define PIPELINE_PHASES dict:
     ```python
     PIPELINE_PHASES = {
         'ingest': {'id': 'CP_INGEST', 'order': 1, 'markers': ['inbox/', 'ingest']},
         'chunk': {'id': 'CP_CHUNK', 'order': 2, 'markers': ['chunks/', 'CHUNKS-STATE']},
         'canonical': {'id': 'CP_CANONICAL', 'order': 3, 'markers': ['canonical/', 'entities']}
     }
     ```

3. **State management functions** (~60 lines):
   - `load_state() -> Dict`: Load PIPELINE-STATE.json or return default
   - `save_state(state: Dict) -> bool`: Save state to JSON file
   - `create_default_state() -> Dict`: Return clean state template:
     ```python
     {
         'version': '1.0.0',
         'current_phase': None,
         'phases': {
             'ingest': {'status': 'pending', 'files': [], 'timestamp': None},
             'chunk': {'status': 'pending', 'files': [], 'timestamp': None},
             'canonical': {'status': 'pending', 'files': [], 'timestamp': None}
         },
         'last_checkpoint': None,
         'history': []
     }
     ```

4. **Phase detection** (~40 lines):
   - `detect_phase_from_path(file_path: str) -> Optional[str]`:
     Check file path against PIPELINE_PHASES markers
   - `detect_phase_completion(tool_input: Dict) -> Optional[str]`:
     Check if tool output indicates phase completion (look for STATE.json updates)

5. **Checkpoint operations** (~50 lines):
   - `save_checkpoint(phase: str, files: List[str], status: str) -> Dict`:
     Update state with phase completion, add to history
   - `can_retry_phase(phase: str) -> bool`:
     Check if phase can be retried (status == 'failed' or 'pending')
   - `get_resume_point() -> Optional[str]`:
     Return the phase to resume from (first incomplete phase)

6. **Logging** (~15 lines):
   - `log_checkpoint(action: Dict) -> None`:
     Append to pipeline-checkpoints.jsonl

7. **Main hook entry** (~40 lines):
   - Read stdin for hook input
   - Extract tool_input (file_path, content if available)
   - Detect which phase was affected
   - If phase detected and file written successfully:
     - Update state with file processed
     - Check if phase completed (all expected files written)
     - Save checkpoint if phase completed
   - Output: `{'continue': True, 'feedback': feedback_if_any}`

Key detection patterns:
- Ingest phase: Files in `inbox/` or containing 'ingest' markers
- Chunk phase: Files in `processing/chunks/` or `CHUNKS-STATE.json`
- Canonical phase: Files in `processing/canonical/` or entity-related files
  </action>
  <verify>
    <automated>python3 -c "import sys; sys.path.insert(0, '.claude/hooks'); from pipeline_checkpoint import load_state, create_default_state; state = create_default_state(); print('phases:', list(state['phases'].keys())); assert 'ingest' in state['phases']"</automated>
  </verify>
  <done>
Hook script exists with 150+ lines. Functions load_state, save_state, create_default_state work. Phase detection logic implemented.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create initial PIPELINE-STATE.json and integrate with settings.json</name>
  <files>.claude/mission-control/PIPELINE-STATE.json, .claude/settings.json</files>
  <action>
1. **Create PIPELINE-STATE.json** (~30 lines):
   Create initial state file at .claude/mission-control/PIPELINE-STATE.json:
   ```json
   {
     "version": "1.0.0",
     "current_phase": null,
     "phases": {
       "ingest": {"status": "pending", "files": [], "timestamp": null, "checkpoint_id": "CP_INGEST"},
       "chunk": {"status": "pending", "files": [], "timestamp": null, "checkpoint_id": "CP_CHUNK"},
       "canonical": {"status": "pending", "files": [], "timestamp": null, "checkpoint_id": "CP_CANONICAL"}
     },
     "last_checkpoint": null,
     "history": [],
     "retry_enabled": true
   }
   ```

2. **Update settings.json** to add the hook:
   Add to PostToolUse hooks array (after existing hooks):
   ```json
   {
     "type": "command",
     "command": "python3 .claude/hooks/pipeline_checkpoint.py",
     "timeout": 5000
   }
   ```

   The hook should be added to the existing PostToolUse block with matcher "Edit|Write|MultiEdit".
  </action>
  <verify>
    <automated>python3 -c "import json; state=json.load(open('.claude/mission-control/PIPELINE-STATE.json')); settings=json.load(open('.claude/settings.json')); hooks=[h for g in settings['hooks']['PostToolUse'] for h in g.get('hooks', [])]; print('state version:', state['version']); print('hook registered:', any('pipeline_checkpoint' in h.get('command','') for h in hooks))"</automated>
  </verify>
  <done>
PIPELINE-STATE.json exists with correct structure. settings.json contains pipeline_checkpoint.py in PostToolUse hooks.
  </done>
</task>

<task type="auto">
  <name>Task 3: Add retry and resume capabilities</name>
  <files>.claude/hooks/pipeline_checkpoint.py</files>
  <action>
Enhance the hook with retry and resume capabilities:

1. **Add CLI interface** (~30 lines):
   Allow direct execution for debugging and manual operations:
   ```python
   if __name__ == "__main__":
       if len(sys.argv) > 1:
           command = sys.argv[1]
           if command == 'status':
               # Print current pipeline status
           elif command == 'retry':
               # Mark specified phase for retry
               phase = sys.argv[2] if len(sys.argv) > 2 else None
           elif command == 'resume':
               # Get resume point
           elif command == 'reset':
               # Reset state to clean
   ```

2. **Add mark_for_retry function** (~20 lines):
   - Set phase status to 'retry_pending'
   - Clear files list for that phase
   - Log the retry request

3. **Add get_pipeline_status function** (~25 lines):
   - Return formatted status of all phases
   - Include: phase, status, file count, last timestamp
   - Useful for `/jarvis-briefing` integration

4. **Update main to handle retry scenario** (~15 lines):
   - Before processing, check if current phase is in 'retry_pending'
   - If so, allow reprocessing and update status to 'in_progress'

5. **Add validation on phase completion** (~20 lines):
   - Before marking phase as 'complete', verify:
     - At least one file was processed
     - State file exists (for chunk and canonical phases)
   - If validation fails, mark as 'needs_attention'
  </action>
  <verify>
    <automated>python3 .claude/hooks/pipeline_checkpoint.py status 2>/dev/null | grep -q "ingest" && echo "status command works"</automated>
  </verify>
  <done>
Hook supports CLI commands: status, retry, resume, reset. Retry functionality marks phase for reprocessing. Status command shows pipeline state.
  </done>
</task>

</tasks>

<verification>
1. pipeline_checkpoint.py exists and has 150+ lines
2. PIPELINE-STATE.json exists with correct structure (version, phases, retry_enabled)
3. settings.json contains pipeline_checkpoint.py in PostToolUse hooks
4. Running `python3 .claude/hooks/pipeline_checkpoint.py status` shows pipeline state
5. Running `python3 .claude/hooks/pipeline_checkpoint.py retry ingest` marks ingest for retry
6. Hook properly detects phase from file paths (test with mock file paths)
</verification>

<success_criteria>
- HOOK-01 complete: Checkpoint hook for Phase 1 (Ingest) saves state with phase, files, timestamp
- HOOK-02 complete: Checkpoint hook for Phase 2 (Chunk) saves state with phase, files, timestamp
- HOOK-03 complete: Checkpoint hook for Phase 3 (Canonical) saves state with phase, files, timestamp
- All phases support retry via CLI command
- Hook integrated with settings.json PostToolUse
- State persists in PIPELINE-STATE.json
</success_criteria>

<output>
After completion, create `.planning/phases/03-checkpoint-hooks/03-01-SUMMARY.md`
</output>
