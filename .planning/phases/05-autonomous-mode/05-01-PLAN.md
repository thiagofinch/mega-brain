---
phase: 05-autonomous-mode
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - core/intelligence/autonomous_processor.py
  - core/intelligence/__init__.py
autonomous: true
requirements:
  - AUTO-01
  - AUTO-02
  - AUTO-03
  - AUTO-06

must_haves:
  truths:
    - "Queue accepts files and returns them in FIFO order with priority support"
    - "Loop processes files until queue is empty or stop signal received"
    - "Failed files are retried up to 3 times with exponential backoff"
    - "Files exceeding timeout are marked as failed and moved to next"
  artifacts:
    - path: "core/intelligence/autonomous_processor.py"
      provides: "Autonomous processor with Queue, Loop, Recovery, Timeout"
      min_lines: 400
      exports:
        - AutonomousProcessor
        - FileQueue
        - ProcessingResult
  key_links:
    - from: "core/intelligence/autonomous_processor.py"
      to: "core/intelligence/task_orchestrator.py"
      via: "TaskOrchestrator import"
      pattern: "from.*task_orchestrator.*import"
---

<objective>
Create the core autonomous processing engine with Queue, Loop, Recovery, and Timeout systems.

Purpose: Enable unattended file processing with automatic retry and timeout handling
Output: `autonomous_processor.py` module with all core autonomous capabilities
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-task-orchestrator/04-01-SUMMARY.md
@.planning/phases/04-task-orchestrator/04-02-SUMMARY.md
@core/intelligence/task_orchestrator.py
</context>

<interfaces>
<!-- Key types and contracts the executor needs. From existing codebase. -->

From core/intelligence/task_orchestrator.py:
```python
@dataclass
class ExecutionState:
    workflow_id: str
    current_phase: Optional[str] = None
    current_step: int = 0
    status: str = "not_started"
    history: List[Dict[str, Any]] = field(default_factory=list)
    started_at: Optional[str] = None
    completed_at: Optional[str] = None
    phase_outputs: Dict[str, Any] = field(default_factory=dict)
    task_timings: Dict[str, float] = field(default_factory=dict)

class TaskOrchestrator:
    def __init__(self, workflow_id: str): ...
    def execute(self, inputs: Dict[str, Any]) -> Dict[str, Any]: ...
    def get_progress(self) -> ProgressReport: ...

def save_state(state: ExecutionState) -> None: ...
def load_state() -> Optional[ExecutionState]: ...
def log_execution(event: Dict[str, Any]) -> None: ...
```

State file pattern:
- Location: `.claude/mission-control/{NAME}-STATE.json`
- Format: JSON with version, status, timestamps
- Logging: JSONL to `logs/{name}.jsonl`
</interfaces>

<tasks>

<task type="auto">
  <name>Task 1: Create FileQueue with priority and persistence</name>
  <files>core/intelligence/autonomous_processor.py</files>
  <action>
Create `core/intelligence/autonomous_processor.py` with FileQueue class:

```python
# Constants
QUEUE_STATE_PATH = PROJECT_DIR / '.claude' / 'mission-control' / 'QUEUE-STATE.json'

@dataclass
class QueueItem:
    file_path: str
    priority: int = 0  # Higher = more priority
    added_at: str = ""
    attempts: int = 0
    last_attempt: Optional[str] = None
    status: str = "pending"  # pending, processing, completed, failed, timeout

class FileQueue:
    """FIFO queue with priority support and persistence."""

    def __init__(self):
        self.items: List[QueueItem] = []
        self._load()

    def add(self, file_path: str, priority: int = 0) -> None:
        """Add file to queue. Higher priority = processed first."""

    def pop(self) -> Optional[QueueItem]:
        """Get next file (highest priority first, then FIFO)."""

    def peek(self) -> Optional[QueueItem]:
        """Preview next file without removing."""

    def mark_complete(self, file_path: str, success: bool) -> None:
        """Mark file as completed or failed."""

    def mark_timeout(self, file_path: str) -> None:
        """Mark file as timed out."""

    def get_pending(self) -> List[QueueItem]:
        """Get all pending items."""

    def get_failed(self) -> List[QueueItem]:
        """Get all failed items (for retry consideration)."""

    def is_empty(self) -> bool:
        """Check if queue has no pending items."""

    def size(self) -> int:
        """Return count of pending items."""

    def _load(self) -> None:
        """Load queue from disk."""

    def _save(self) -> None:
        """Persist queue to disk."""

    def clear(self) -> None:
        """Clear all items."""
```

Key implementation details:
- Use `dataclasses.asdict()` for JSON serialization
- Sort by priority (desc) then added_at (asc) when popping
- Auto-save after every mutation
- Include `version: "1.0.0"` in state file
  </action>
  <verify>
```bash
python3 -c "
from core.intelligence.autonomous_processor import FileQueue, QueueItem
q = FileQueue()
q.clear()
q.add('/test/a.txt', priority=0)
q.add('/test/b.txt', priority=1)
item = q.pop()
assert item.file_path == '/test/b.txt', 'Higher priority should pop first'
assert q.size() == 1
print('FileQueue: PASSED')
"
```
  </verify>
  <done>FileQueue persists to QUEUE-STATE.json, supports priority ordering, tracks item status</done>
</task>

<task type="auto">
  <name>Task 2: Create processing loop with stop signal and recovery</name>
  <files>core/intelligence/autonomous_processor.py</files>
  <action>
Add AutonomousProcessor class to autonomous_processor.py:

```python
# Constants
STOP_SIGNAL_PATH = PROJECT_DIR / '.claude' / 'mission-control' / 'STOP-AUTONOMOUS'
PROCESSOR_STATE_PATH = PROJECT_DIR / '.claude' / 'mission-control' / 'AUTONOMOUS-STATE.json'
LOG_PATH = PROJECT_DIR / 'logs' / 'autonomous-processing.jsonl'

DEFAULT_TIMEOUT_SECONDS = 300  # 5 minutes
MAX_RETRIES = 3
BACKOFF_BASE = 2  # Exponential: 2^attempt seconds

@dataclass
class ProcessingResult:
    file_path: str
    success: bool
    error: Optional[str] = None
    duration_seconds: float = 0
    attempts: int = 1

@dataclass
class ProcessorState:
    status: str = "idle"  # idle, running, stopped, completed
    started_at: Optional[str] = None
    stopped_at: Optional[str] = None
    files_processed: int = 0
    files_failed: int = 0
    current_file: Optional[str] = None

class AutonomousProcessor:
    """Main autonomous processing engine."""

    def __init__(self, workflow_id: str = "wf-pipeline-full"):
        self.queue = FileQueue()
        self.orchestrator = TaskOrchestrator(workflow_id)
        self.state = self._load_state()
        self.timeout_seconds = DEFAULT_TIMEOUT_SECONDS

    def run(self, timeout_seconds: Optional[int] = None) -> Dict[str, Any]:
        """
        Process files until queue empty or stop signal received.

        Args:
            timeout_seconds: Override default timeout per file

        Returns:
            Dict with stats: processed, failed, stopped_by
        """
        # Implementation:
        # 1. Set state to running
        # 2. Loop while not stopped and queue not empty:
        #    a. Check stop signal (STOP-AUTONOMOUS file exists)
        #    b. Pop next file
        #    c. Process with timeout
        #    d. Handle result (success/failure/timeout)
        #    e. If failed and attempts < MAX_RETRIES: re-queue with backoff
        #    f. Log event
        # 3. Set state to completed/stopped
        # 4. Return stats

    def stop(self) -> None:
        """Create stop signal file."""
        STOP_SIGNAL_PATH.touch()

    def _should_stop(self) -> bool:
        """Check if stop signal exists."""
        return STOP_SIGNAL_PATH.exists()

    def _clear_stop_signal(self) -> None:
        """Remove stop signal file."""
        if STOP_SIGNAL_PATH.exists():
            STOP_SIGNAL_PATH.unlink()

    def _process_file(self, item: QueueItem) -> ProcessingResult:
        """
        Process a single file with timeout.

        Uses signal.alarm() for timeout on Unix.
        Wraps orchestrator.execute() call.
        """

    def _should_retry(self, item: QueueItem) -> bool:
        """Check if item should be retried (attempts < MAX_RETRIES)."""
        return item.attempts < MAX_RETRIES

    def _calculate_backoff(self, attempts: int) -> float:
        """Calculate exponential backoff: 2^attempts seconds."""
        return BACKOFF_BASE ** attempts

    def _requeue_with_backoff(self, item: QueueItem) -> None:
        """Re-add item to queue after backoff delay."""
        # Note: For simplicity, just increment attempts and re-add
        # Backoff is tracked but not enforced with sleep (let caller decide)

    def _load_state(self) -> ProcessorState:
        """Load processor state from disk."""

    def _save_state(self) -> None:
        """Persist processor state."""

    def _log_event(self, event: Dict[str, Any]) -> None:
        """Append event to JSONL log."""

    def get_status(self) -> Dict[str, Any]:
        """Return current processor status."""
```

Key implementation details:
- Use `signal.SIGALRM` for Unix timeout (with try/except for Windows fallback)
- Stop signal is a file: touch to stop, delete to reset
- Log all events: file_started, file_completed, file_failed, file_timeout, processor_stopped
- Exponential backoff: 2s, 4s, 8s for retries 1, 2, 3
  </action>
  <verify>
```bash
python3 -c "
from core.intelligence.autonomous_processor import AutonomousProcessor, FileQueue
from pathlib import Path
import os

# Setup
proc = AutonomousProcessor('wf-ingest')
proc.queue.clear()

# Test stop signal
stop_path = Path('.claude/mission-control/STOP-AUTONOMOUS')
stop_path.unlink(missing_ok=True)
assert not proc._should_stop()
proc.stop()
assert proc._should_stop()
proc._clear_stop_signal()
assert not proc._should_stop()

# Test backoff calculation
assert proc._calculate_backoff(1) == 2
assert proc._calculate_backoff(2) == 4
assert proc._calculate_backoff(3) == 8

print('AutonomousProcessor: PASSED')
"
```
  </verify>
  <done>AutonomousProcessor runs loop until empty/stop, retries with exponential backoff, respects timeout</done>
</task>

<task type="auto">
  <name>Task 3: Add CLI commands and module exports</name>
  <files>core/intelligence/autonomous_processor.py, core/intelligence/__init__.py</files>
  <action>
Add CLI interface to autonomous_processor.py:

```python
def print_usage():
    print("""
Autonomous Processor - Mega Brain Pipeline
===========================================

Usage:
    python3 autonomous_processor.py <command> [args]

Commands:
    queue add <file> [priority]   Add file to queue
    queue list                    List pending files
    queue clear                   Clear queue
    queue size                    Show queue size
    run [--timeout=300]           Start processing
    stop                          Send stop signal
    status                        Show processor status
    retry-failed                  Re-queue all failed files

Examples:
    python3 autonomous_processor.py queue add inbox/file.txt 1
    python3 autonomous_processor.py run --timeout=600
    python3 autonomous_processor.py stop
    """)

def main():
    import sys
    if len(sys.argv) < 2:
        print_usage()
        sys.exit(1)

    command = sys.argv[1].lower()

    if command == 'queue':
        # Handle: add, list, clear, size
        ...
    elif command == 'run':
        # Parse --timeout=N if provided
        ...
    elif command == 'stop':
        ...
    elif command == 'status':
        ...
    elif command == 'retry-failed':
        ...
    else:
        print_usage()
        sys.exit(1)

if __name__ == '__main__':
    main()

__all__ = [
    'AutonomousProcessor',
    'FileQueue',
    'QueueItem',
    'ProcessingResult',
    'ProcessorState',
]
```

Update `core/intelligence/__init__.py`:
- Add imports for AutonomousProcessor, FileQueue, ProcessingResult
- Add to __all__ list
  </action>
  <verify>
```bash
python3 core/intelligence/autonomous_processor.py queue size && \
python3 core/intelligence/autonomous_processor.py status && \
python3 -c "from core.intelligence import AutonomousProcessor, FileQueue; print('Imports: OK')"
```
  </verify>
  <done>CLI commands work, module exports are available from core.intelligence</done>
</task>

</tasks>

<verification>
All AUTO-01, AUTO-02, AUTO-03, AUTO-06 requirements implemented:
1. `queue add/list/size` commands work
2. `run` command processes until empty or stop
3. Failed files retry up to 3x with backoff
4. Timeout kills long-running files
5. Module exports available from `core.intelligence`
</verification>

<success_criteria>
- FileQueue persists to QUEUE-STATE.json with priority ordering
- AutonomousProcessor.run() processes until queue empty or stop signal
- Failed files get 3 retries with exponential backoff (2s, 4s, 8s)
- Files exceeding timeout are marked failed and processing continues
- CLI commands: queue add/list/clear/size, run, stop, status
- All classes exported from core.intelligence module
</success_criteria>

<output>
After completion, create `.planning/phases/05-autonomous-mode/05-01-SUMMARY.md`
</output>
