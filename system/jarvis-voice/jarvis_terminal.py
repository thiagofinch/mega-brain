#!/usr/bin/env python3
"""
JARVIS TERMINAL - Interface de Voz Local
=========================================
Assistente de voz JARVIS rodando direto no terminal.
- STT: Deepgram Nova-2 (otimizado para PT-BR)
- LLM: Claude (Anthropic)
- TTS: ElevenLabs JARVIS v4

Uso: python jarvis_terminal.py
"""

import asyncio
import io
import os
import sys
import wave
import tempfile
from pathlib import Path

import numpy as np
import pyaudio
import requests
from anthropic import Anthropic
from dotenv import load_dotenv

load_dotenv()

# Configura√ß√µes
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")
if not ANTHROPIC_API_KEY:
    raise ValueError("ANTHROPIC_API_KEY not set in environment")
DEEPGRAM_API_KEY = os.getenv("DEEPGRAM_API_KEY", "")
ELEVENLABS_API_KEY = os.getenv("ELEVENLABS_API_KEY")
if not ELEVENLABS_API_KEY:
    raise ValueError("ELEVENLABS_API_KEY not set in environment")
JARVIS_VOICE_ID = os.environ.get("ELEVENLABS_TERMINAL_VOICE_ID", "your-voice-id-here")

# System prompt JARVIS
JARVIS_SYSTEM_PROMPT = """Voc√™ √© JARVIS - Just A Rather Very Intelligent System.
Assistente pessoal do senhor, business professional.

REGRAS DE IDIOMA (OBRIGAT√ìRIO):
- SEMPRE fale em PORTUGU√äS BRASILEIRO (PT-BR)
- NUNCA use portugu√™s de Portugal
- Use "voc√™" (n√£o "tu"), "celular" (n√£o "telem√≥vel"), "legal" (n√£o "fixe")

PERSONALIDADE:
- Tom sofisticado, elegante, preciso
- Levemente ir√¥nico quando apropriado
- Chame o usu√°rio de "senhor"
- Seja CONCISO (m√°ximo 2-3 frases por resposta)

IMPORTANTE: Respostas curtas pois ser√£o faladas em voz alta."""


class JarvisTerminal:
    """Interface de voz JARVIS para terminal."""

    def __init__(self):
        # Audio config
        self.audio_format = pyaudio.paInt16
        self.channels = 1
        self.rate = 16000
        self.chunk = 1024
        self.silence_threshold = 500
        self.silence_duration = 1.5

        # Initialize audio
        self.audio = pyaudio.PyAudio()

        # Initialize clients
        self.anthropic = Anthropic(api_key=ANTHROPIC_API_KEY)
        self.conversation_history = []

        # Check pygame for audio playback
        try:
            import pygame
            pygame.mixer.init()
            self.pygame = pygame
        except ImportError:
            self.pygame = None
            print("‚ö†Ô∏è  pygame n√£o instalado - usando afplay para √°udio")

    def print_header(self):
        """Print JARVIS header."""
        print("\n" + "=" * 60)
        print("""
       ‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó
       ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù
       ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó
  ‚ñà‚ñà   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ïö‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë‚ïö‚ïê‚ïê‚ïê‚ïê‚ñà‚ñà‚ïë
  ‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë ‚ïö‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë
   ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

         TERMINAL VOICE INTERFACE v1.0
        """)
        print("=" * 60)
        print("\nüé§ Fale algo ou digite 'sair' para encerrar")
        print("üì¢ Pressione CTRL+C para interromper\n")

    def detect_silence(self, audio_data: bytes) -> bool:
        """Detecta sil√™ncio no √°udio."""
        audio_array = np.frombuffer(audio_data, dtype=np.int16)
        return np.max(np.abs(audio_array)) < self.silence_threshold

    def record_audio(self) -> bytes | None:
        """Grava √°udio do microfone."""
        print("\nüé§ Ouvindo... (fale agora)")

        try:
            stream = self.audio.open(
                format=self.audio_format,
                channels=self.channels,
                rate=self.rate,
                input=True,
                frames_per_buffer=self.chunk,
            )

            frames = []
            silence_frames = 0
            silence_frame_threshold = int(self.rate / self.chunk * self.silence_duration)
            has_speech = False

            while True:
                data = stream.read(self.chunk, exception_on_overflow=False)
                frames.append(data)

                if self.detect_silence(data):
                    silence_frames += 1
                    if has_speech and silence_frames > silence_frame_threshold:
                        break
                else:
                    silence_frames = 0
                    has_speech = True

                # Max 30 seconds
                if len(frames) > self.rate / self.chunk * 30:
                    break

            stream.stop_stream()
            stream.close()

            if not has_speech:
                print("‚ùå Nenhuma fala detectada.")
                return None

            print("‚è≥ Processando...")
            return b"".join(frames)

        except Exception as e:
            print(f"‚ùå Erro gravando √°udio: {e}")
            return None

    def audio_to_text_deepgram(self, audio_data: bytes) -> str | None:
        """Converte √°udio para texto usando Deepgram."""
        try:
            # Create WAV in memory
            wav_buffer = io.BytesIO()
            with wave.open(wav_buffer, "wb") as wf:
                wf.setnchannels(self.channels)
                wf.setsampwidth(self.audio.get_sample_size(self.audio_format))
                wf.setframerate(self.rate)
                wf.writeframes(audio_data)

            wav_buffer.seek(0)

            # Send to Deepgram
            response = requests.post(
                "https://api.deepgram.com/v1/listen",
                headers={
                    "Authorization": f"Token {DEEPGRAM_API_KEY}",
                    "Content-Type": "audio/wav"
                },
                params={
                    "model": "nova-2",
                    "language": "pt-BR",
                    "smart_format": "true",
                    "punctuate": "true"
                },
                data=wav_buffer.read()
            )

            if response.status_code == 200:
                result = response.json()
                transcript = result.get("results", {}).get("channels", [{}])[0].get("alternatives", [{}])[0].get("transcript", "")
                return transcript.strip() if transcript else None
            else:
                print(f"‚ùå Deepgram erro: {response.status_code}")
                return None

        except Exception as e:
            print(f"‚ùå Erro transcrevendo: {e}")
            return None

    def audio_to_text_whisper(self, audio_data: bytes) -> str | None:
        """Fallback: Whisper local via whisper.cpp ou openai-whisper."""
        try:
            # Try using openai whisper locally
            import whisper

            # Save to temp file
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
                with wave.open(f, "wb") as wf:
                    wf.setnchannels(self.channels)
                    wf.setsampwidth(self.audio.get_sample_size(self.audio_format))
                    wf.setframerate(self.rate)
                    wf.writeframes(audio_data)
                temp_path = f.name

            model = whisper.load_model("base")
            result = model.transcribe(temp_path, language="pt")
            os.unlink(temp_path)

            return result["text"].strip()
        except ImportError:
            print("‚ö†Ô∏è  whisper n√£o instalado")
            return None
        except Exception as e:
            print(f"‚ùå Erro Whisper: {e}")
            return None

    def text_to_speech(self, text: str) -> bool:
        """Converte texto para voz usando ElevenLabs JARVIS v4."""
        try:
            response = requests.post(
                f"https://api.elevenlabs.io/v1/text-to-speech/{JARVIS_VOICE_ID}",
                headers={
                    "xi-api-key": ELEVENLABS_API_KEY,
                    "Content-Type": "application/json"
                },
                json={
                    "text": text,
                    "model_id": "eleven_turbo_v2_5",
                    "voice_settings": {
                        "stability": 0.65,
                        "similarity_boost": 0.92,
                        "style": 0.10,
                        "use_speaker_boost": True
                    }
                }
            )

            if response.status_code == 200:
                # Save and play
                temp_file = tempfile.NamedTemporaryFile(suffix=".mp3", delete=False)
                temp_file.write(response.content)
                temp_file.close()

                # Play audio
                if self.pygame:
                    self.pygame.mixer.music.load(temp_file.name)
                    self.pygame.mixer.music.play()
                    while self.pygame.mixer.music.get_busy():
                        self.pygame.time.Clock().tick(10)
                else:
                    # macOS fallback
                    os.system(f"afplay {temp_file.name}")

                os.unlink(temp_file.name)
                return True
            else:
                print(f"‚ùå ElevenLabs erro: {response.status_code}")
                return False

        except Exception as e:
            print(f"‚ùå Erro TTS: {e}")
            return False

    def process_with_claude(self, text: str) -> str:
        """Processa comando com Claude."""
        try:
            # Add to history
            self.conversation_history.append({
                "role": "user",
                "content": text
            })

            # Call Claude
            response = self.anthropic.messages.create(
                model="claude-3-5-haiku-20241022",
                max_tokens=300,
                system=JARVIS_SYSTEM_PROMPT,
                messages=self.conversation_history
            )

            assistant_message = response.content[0].text

            # Add to history
            self.conversation_history.append({
                "role": "assistant",
                "content": assistant_message
            })

            # Keep history manageable
            if len(self.conversation_history) > 20:
                self.conversation_history = self.conversation_history[-20:]

            return assistant_message

        except Exception as e:
            return f"Desculpe senhor, encontrei um erro: {str(e)}"

    def run(self):
        """Loop principal."""
        self.print_header()

        # Sauda√ß√£o inicial
        greeting = "JARVIS online, senhor. Todos os sistemas operacionais."
        print(f"\nü§ñ JARVIS: {greeting}")
        self.text_to_speech(greeting)

        try:
            while True:
                # Record
                audio_data = self.record_audio()
                if not audio_data:
                    continue

                # STT - Try Deepgram first
                if DEEPGRAM_API_KEY:
                    text = self.audio_to_text_deepgram(audio_data)
                else:
                    text = self.audio_to_text_whisper(audio_data)

                if not text:
                    continue

                print(f"\nüë§ Voc√™: {text}")

                # Check exit
                if text.lower() in ["sair", "exit", "quit", "encerrar", "tchau"]:
                    farewell = "At√© logo, senhor. JARVIS desligando."
                    print(f"\nü§ñ JARVIS: {farewell}")
                    self.text_to_speech(farewell)
                    break

                # Process with Claude
                response = self.process_with_claude(text)
                print(f"\nü§ñ JARVIS: {response}")

                # TTS
                self.text_to_speech(response)

        except KeyboardInterrupt:
            print("\n\n‚ö†Ô∏è  Interrompido pelo usu√°rio.")
        finally:
            self.audio.terminate()
            if self.pygame:
                self.pygame.mixer.quit()


def check_dependencies():
    """Verifica depend√™ncias necess√°rias."""
    missing = []

    try:
        import pyaudio
    except ImportError:
        missing.append("pyaudio")

    try:
        import numpy
    except ImportError:
        missing.append("numpy")

    try:
        import requests
    except ImportError:
        missing.append("requests")

    try:
        from anthropic import Anthropic
    except ImportError:
        missing.append("anthropic")

    if missing:
        print("‚ùå Depend√™ncias faltando:")
        print(f"   pip install {' '.join(missing)}")
        return False

    return True


def check_api_keys():
    """Verifica API keys."""
    issues = []

    if not ANTHROPIC_API_KEY:
        issues.append("ANTHROPIC_API_KEY n√£o configurada")

    if not DEEPGRAM_API_KEY:
        print("‚ö†Ô∏è  DEEPGRAM_API_KEY n√£o configurada - tentar√° usar Whisper local")

    if not ELEVENLABS_API_KEY:
        issues.append("ELEVENLABS_API_KEY n√£o configurada")

    if issues:
        print("‚ùå Problemas de configura√ß√£o:")
        for issue in issues:
            print(f"   ‚Ä¢ {issue}")
        print("\nConfigure as vari√°veis de ambiente:")
        print("   export ANTHROPIC_API_KEY='sua-chave'")
        print("   export DEEPGRAM_API_KEY='sua-chave'")
        return False

    return True


if __name__ == "__main__":
    print("\nüîç Verificando sistema...")

    if not check_dependencies():
        sys.exit(1)

    if not check_api_keys():
        sys.exit(1)

    print("‚úÖ Sistema pronto!\n")

    jarvis = JarvisTerminal()
    jarvis.run()
